{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0b036c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with MLflow Experiment Tracking\n",
    "\n",
    "This notebook integrates MLflow into the Sentiment Analysis project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8f32f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/08 23:10:00 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment-Analysis-Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI: http://127.0.0.1:5000\n",
      "Working directory: c:\\Users\\newtp\\OneDrive\\Desktop\\Sentiment_Analysis_Deployment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Point notebook to the SAME MLflow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Create / set experiment explicitly\n",
    "mlflow.set_experiment(\"Sentiment-Analysis-Experiment\")\n",
    "\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58356b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1770572400421, experiment_id='1', last_update_time=1770572400421, lifecycle_stage='active', name='Sentiment-Analysis-Experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mlflow.set_experiment(\"Sentiment-Analysis-Experiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174cce6",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70df856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7895, 8)\n",
      "Class distribution:\n",
      "Ratings\n",
      "1    6823\n",
      "0    1072\n",
      "Name: count, dtype: int64\n",
      "(6316,)\n",
      "(1579,)\n",
      "(6316,)\n",
      "(1579,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Remove rows with missing review text\n",
    "df = df.dropna(subset=[\"Review text\"])\n",
    "\n",
    "# Remove neutral reviews\n",
    "df = df[df[\"Ratings\"] != 3]\n",
    "\n",
    "# Features and labels\n",
    "X = df[\"Review text\"]\n",
    "y = df[\"Ratings\"].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd301b",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0351d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_features = 5000\n",
    "vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd1450",
   "metadata": {},
   "source": [
    "## Model Training with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb9acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/08 23:10:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\newtp\\anaconda3\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged in MLflow\n",
      "üèÉ View run LogisticRegression_TFIDF at: http://127.0.0.1:5000/#/experiments/1/runs/7fe38966983544019115947a1eea72be\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_TFIDF\"):\n",
    "\n",
    "    C = 1.0\n",
    "    max_iter = 1000\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=max_iter)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    joblib.dump(model, \"sentiment_model.pkl\")\n",
    "    joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "    mlflow.log_artifact(\"sentiment_model.pkl\")\n",
    "    mlflow.log_artifact(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "    print(\"Run logged in MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae6d5c",
   "metadata": {},
   "source": [
    "## Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6e498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.9398\n",
      "Precision : 0.9428\n",
      "Recall    : 0.9905\n",
      "F1 Score  : 0.9661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1 Score  : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243fd3e",
   "metadata": {},
   "source": [
    "## Model Registration\n",
    "Replace <RUN_ID> with your MLflow run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a81c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'SentimentAnalysisModel'.\n",
      "2026/02/08 23:10:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: SentimentAnalysisModel, version 1\n",
      "Created version '1' of model 'SentimentAnalysisModel'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1770572413757, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1770572413757, metrics=None, model_id=None, name='SentimentAnalysisModel', params=None, run_id='', run_link='', source='http://127.0.0.1:5000/model', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " mlflow.register_model(\n",
    "     \"http://127.0.0.1:5000/model\",\n",
    "     \"SentimentAnalysisModel\"\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2a3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
